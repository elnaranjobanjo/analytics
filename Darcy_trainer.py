import csv
import dolfin
import fenics as fe
import json
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import os
import pandas as pd
from dataclasses import dataclass, field
import random

# Given a triplet [eig_1,eig_2,theta] the factory class
# trains a pair of darcy nets u,p solving
#       div u = f
#    A grad p = u
#           p = 0  b.c.
# with A sym. pos. def. with eigen vals eig_1 and eig_2
# The matrix of eigvecs is the rotation matrix generated by theta


def make_Darcy_model_space(mesh: fe.Mesh, degree: int) -> fe.FunctionSpace:
    # Hdiv-L2 conforming FE space.
    return fe.FunctionSpace(
        mesh,
        fe.FiniteElement("BDM", mesh.ufl_cell(), degree)
        * fe.FiniteElement("DG", mesh.ufl_cell(), degree - 1),
    )


class Darcy_nn(nn.Module):
    def __init__(
        self, input_size: int = 3, hidden_size: int = 64, output_size: int = 1
    ):
        super(Darcy_nn, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, hidden_size)
        self.fc4 = nn.Linear(hidden_size, hidden_size)
        self.fc5 = nn.Linear(hidden_size, hidden_size)
        self.fc6 = nn.Linear(hidden_size, output_size)
        self.activation = nn.GELU()

    def forward(self, x: torch.tensor):
        x = self.activation(self.fc1(x))
        x = self.activation(self.fc2(x))
        x = self.activation(self.fc3(x))
        x = self.activation(self.fc4(x))
        x = self.activation(self.fc5(x))
        x = self.fc6(x)
        return x


def get_A_matrix_from(A_matrix_params: list):
    eigen_1 = A_matrix_params[0]
    eigen_2 = A_matrix_params[1]
    theta = A_matrix_params[2]
    return (
        np.array([[np.cos(theta), np.sin(theta)], [-np.sin(theta), np.cos(theta)]])
        * np.array([[eigen_1, 0], [0, eigen_2]])
        * np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])
    )


@dataclass
class DarcyPDELossParams:
    h: float = 0.1
    mesh: fe.Mesh = fe.UnitSquareMesh(10, 10)
    degree: int = 1
    f: str = "10"


def get_matrix_params_from(A: np.array) -> list:
    eig_vals, eig_vecs = np.linalg.eig(A)
    # When A is symmetric eig_vecs is a rotation matrix
    cos_theta = eig_vecs[0, 0]
    sin_theta = eig_vecs[1, 0]
    return [eig_vals[0], eig_vals[1], np.arctan2(sin_theta, cos_theta)]


class Darcy_PDE_Loss(nn.Module):
    def __init__(self, params: DarcyPDELossParams):
        super(Darcy_PDE_Loss, self).__init__()
        self.lossfun = nn.MSELoss()
        self.model_space = make_Darcy_model_space(params.mesh, params.degree)

        # Define the test functions
        (v, q) = fe.TestFunctions(self.model_space)

        # Build the right-hand side vector L
        L = fe.Expression(params.f, degree=params.degree - 1) * q * fe.dx
        L_np = fe.assemble(L).get_local()
        self.f = torch.from_numpy(L_np).float()

    def forward(
        self, u_dofs: torch.tensor, p_dofs: torch.tensor, A_matrix_params: list
    ):
        w = torch.cat((u_dofs, p_dofs), dim=0)
        return self.lossfun(
            torch.matmul(self.assemble_system(A_matrix_params), w), self.f
        )

    def assemble_system(self, A_matrix_params: list):
        Ainv = np.linalg.inv(get_A_matrix_from(A_matrix_params))

        # Define the trial and test functions
        (u, p) = fe.TrialFunctions(self.model_space)
        (v, q) = fe.TestFunctions(self.model_space)

        lhs_matrix = fe.dot(fe.Constant(Ainv) * u, v) + fe.div(v) * p + fe.div(u) * q
        a_np = fe.assemble(lhs_matrix * fe.dx).array()
        return torch.from_numpy(a_np).float()


class Darcy_Solver:
    def __init__(self):
        pass

    def init_from_nets(
        self,
        u_net: Darcy_nn,
        p_net: Darcy_nn,
        model_space: fe.FunctionSpace,
    ):
        self.u_net = u_net
        self.p_net = p_net
        self.model_space = model_space
        return self

    def to_fenics(self, A_matrix_params: list):  # -> tuple(fe.Function, fe.Function):
        bias_term = torch.tensor([1], dtype=A_matrix_params.dtype)
        x_with_bias = torch.cat(
            (bias_term, torch.tensor(np.array(A_matrix_params))), dim=0
        )
        u_dofs = self.u.forward(x_with_bias).detach().numpy()
        p_dofs = self.p.forward(x_with_bias).detach().numpy()

        (u, p) = fe.Function(self.model_space).split()

        u.vector().set_local(u_dofs)
        p.vector().set_local(p_dofs)
        return (u, p)

    def save(self, directory_path: str):
        if not os.path.exists(directory_path):
            os.makedirs(directory_path)

        mesh_file = dolfin.File(os.path.join(directory_path, "mesh.xml"))
        mesh_file << self.model_space.mesh()

        dict = {"degree": self.model_space.sub(0).ufl_element().degree()}
        with open(os.path.join(directory_path, "degree.json"), "w") as json_file:
            json.dump(dict, json_file)

        torch.save(self.u_net.state_dict(), os.path.join(directory_path, "u_net.pt"))
        torch.save(self.p_net.state_dict(), os.path.join(directory_path, "p_net.pt"))

    def load(self, directory_path: str):
        with open(os.path.join(directory_path, "degree.json"), "r") as json_file:
            degree_json = json.load(json_file)

        self.model_space = make_Darcy_model_space(
            fe.Mesh(os.path.join(directory_path, "mesh.xml")), degree_json["degree"]
        )

        if torch.cuda.is_available():
            device = torch.device("cuda")
        else:
            device = torch.device("cpu")
        self.u_net = Darcy_nn(
            input_size=4,
            hidden_size=int((2 / 3) * (4 + self.model_space.sub(0).dim())),
            output_size=self.model_space.sub(0).dim(),
        )
        self.u_net.load_state_dict(torch.load(directory_path + "/u_net.pt"))
        self.u_net.to(device)
        self.p_net = Darcy_nn(
            input_size=4,
            hidden_size=int((2 / 3) * (4 + self.model_space.sub(1).dim())),
            output_size=self.model_space.sub(1).dim(),
        )
        self.p_net.load_state_dict(torch.load(directory_path + "/p_net.pt"))
        self.p_net.to(device)
        return self


@dataclass
class DarcynnFactoryParams:
    h: float = 0.1
    mesh: fe.Mesh = fe.UnitSquareMesh(10, 10)
    degree: int = 1
    f: str = "10"
    epochs: int = 100
    learn_rate: float = 0.001
    dataless: bool = True


class Darcy_nn_Factory:
    def __init__(self, params: DarcynnFactoryParams):
        PDE_loss_params = DarcyPDELossParams(
            h=params.h,
            mesh=params.mesh,
            degree=params.degree,
            f=params.f,
        )

        self.PDE_loss = Darcy_PDE_Loss(PDE_loss_params)

        self.epochs = params.epochs
        self.learn_rate = params.learn_rate
        self.input_size = 4
        self.u_output_size = self.PDE_loss.model_space.sub(0).dim()
        self.u_hidden_size = int((2 / 3) * (self.input_size + self.u_output_size))
        self.p_output_size = self.PDE_loss.model_space.sub(1).dim()
        self.p_hidden_size = int((2 / 3) * (self.input_size + self.p_output_size))
        self.dataless = params.dataless
        if not self.dataless:
            pass

    def fit(
        self,
        training_data: list,
        batch_size: int,
        output_dir: str,
        verbose: bool = False,
    ) -> Darcy_Solver:
        if torch.cuda.is_available():
            device = torch.device("cuda")
        else:
            device = torch.device("cpu")
        u_net = Darcy_nn(
            input_size=self.input_size,
            hidden_size=self.u_hidden_size,
            output_size=self.u_output_size,
        ).to(device)

        p_net = Darcy_nn(
            input_size=self.input_size,
            hidden_size=self.p_hidden_size,
            output_size=self.p_output_size,
        ).to(device)

        u_optimizer = torch.optim.Adam(u_net.parameters(), lr=self.learn_rate)
        p_optimizer = torch.optim.Adam(p_net.parameters(), lr=self.learn_rate)

        if self.dataless:
            training_set = TensorDataset(torch.tensor(training_data[0]))
        else:
            training_set = TensorDataset(
                torch.tensor(training_data[0]), torch.tensor(training_data[1])
            )
        batch_loader = DataLoader(
            dataset=training_set, batch_size=batch_size, shuffle=False
        )

        losses = []
        for i in range(self.epochs):
            loss = self.one_grad_descent_iter(
                batch_loader, u_net, p_net, u_optimizer, p_optimizer
            )

            with open(os.path.join(output_dir, "log.txt"), "a") as file:
                file.write(f"epoch number {i}\n")
                file.write(f"Current loss = {loss}\n\n")
            losses.append(loss)

            if verbose:
                print(f"Current loss = {loss}")

        with open(os.path.join(output_dir, "losses.csv"), "w") as csvfile:
            csvwriter = csv.writer(csvfile)
            csvwriter.writerows([[loss] for loss in losses])

        return Darcy_Solver().init_from_nets(u_net, p_net, self.PDE_loss.model_space)

    def one_grad_descent_iter(self, xy_loader, u_net, p_net, u_optimizer, p_optimizer):
        average_loss = []
        u_net.train()
        p_net.train()

        for batch in xy_loader:
            if self.dataless:
                x_batch = batch[0]
                total_loss = self.calculate_PDE_loss(u_net, p_net, x_batch)
                average_loss.append(
                    self.calculate_PDE_loss(u_net, p_net, x_batch).item()
                )
            else:
                x_batch, y_batch = batch
                total_loss = self.calculate_PDE_loss(u_net, p_net, x_batch)

            total_loss.backward()
            u_optimizer.step()
            p_optimizer.step()

        return np.array(average_loss).mean(axis=0)

    def calculate_PDE_loss(self, u_net, p_net, x_batch):
        loss = 0
        for x in x_batch:
            bias_term = torch.tensor([1], dtype=x.dtype)
            x_with_bias = torch.cat((bias_term, x), dim=0)
            loss += self.PDE_loss(u_net(x_with_bias), p_net(x_with_bias), x)

        return loss / len(x_batch)


@dataclass
class DarcyTrainingParams:
    mesh: fe.Mesh = fe.UnitSquareMesh(10, 10)
    degree: int = 1
    f: str = "10"
    A_matrix_params: list[list[float], list[float]] = field(
        default_factory=lambda: [[5, 10], [5, 10]]
    )
    epochs: int = 10
    learn_rate: float = 0.001
    dataless: bool = True
    number_of_training_points: int = 100
    percentage_for_validation: float = 0.2
    batch_size: int = 10


def do_train(params: DarcyTrainingParams, output_dir: str, verbose=False):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    if os.path.exists(os.path.join(output_dir, "log.txt")):
        os.remove(os.path.join(output_dir, "log.txt"))

    if params.dataless:
        A_matrix_params = [
            [
                random.uniform(
                    params.A_matrix_params[0][0], params.A_matrix_params[0][1]
                ),
                random.uniform(
                    params.A_matrix_params[1][0], params.A_matrix_params[1][1]
                ),
                random.uniform(0, 2 * np.pi),
            ]
            for _ in range(params.number_of_training_points)
        ]
        split_index = int(params.percentage_for_validation * len(A_matrix_params))
        X_train, X_val = (
            A_matrix_params[split_index:],
            A_matrix_params[:split_index],
        )
        training_data = [X_train]
        validation_data = [X_val]
    else:
        pass

    factory_params = DarcynnFactoryParams(
        mesh=params.mesh,
        degree=params.degree,
        f=params.f,
        epochs=params.epochs,
        learn_rate=params.learn_rate,
    )

    return Darcy_nn_Factory(factory_params).fit(
        training_data, params.batch_size, output_dir, verbose=verbose
    )


def make_loss_plot(output_dir: str):
    df = pd.read_csv("losses.csv")
    y = df.iloc[:, 0].to_numpy()
    plt.plot(range(1, len(y) + 1), y)
    plt.ylabel("loss")
    plt.xlabel("epochs")
    plt.savefig(os.path.join(output_dir, "loss.png"))


if __name__ == "__main__":
    # params = DarcyTrainingParams(epochs = 2000,learn_rate=0.00001,number_of_training_points=2000, batch_size=100,percentage_for_validation=0)
    params = DarcyTrainingParams(
        epochs=50,
        learn_rate=0.00001,
        number_of_training_points=1000,
        batch_size=100,
        percentage_for_validation=0,
    )
    output_dir = "./output"
    solver = do_train(params, output_dir, verbose=True)
    make_loss_plot(output_dir)
    solver.save(os.path.join(output_dir, "nets"))

    # solver = Darcy_Solver().load(os.path.join(output_dir, "nets"))
